{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMYkrTO+OLgcz7yrjsF1soT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"gFCAW9aLhd3L","executionInfo":{"status":"ok","timestamp":1702845898259,"user_tz":-60,"elapsed":2560,"user":{"displayName":"Baye Cheikh Mbaye","userId":"08929488139517231591"}}},"outputs":[],"source":["# preprocessing.py\n","\n","import re\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","\n","def clean_text(text):\n","    \"\"\"\n","    Nettoie le texte des emails.\n","\n","    Args:\n","    text (str): Texte à nettoyer.\n","\n","    Returns:\n","    str: Texte nettoyé (en minuscules, sans ponctuation, ni chiffres, sans mots vides).\n","    \"\"\"\n","    text = re.sub(r'Subject:', '', text)\n","    text = text.lower()\n","    text = re.sub(r'[^a-zA-Z]', ' ', text)\n","    tokens = word_tokenize(text)\n","    cleaned_text = ' '.join([word for word in tokens if word not in stopwords.words('english')])\n","    return cleaned_text\n"]}]}